{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle房价预测.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlm5YhdWjWTgH8i4its7Z0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuanyibo666/DL_practicecode/blob/main/Kaggle%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import os\n",
        "import tarfile\n",
        "import zipfile\n",
        "import requests\n",
        "import random\n",
        "\n",
        "DATA_HUB = dict()\n",
        "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
        "\n",
        "def download(name, cache_dir=os.path.join('..', 'data')):  \n",
        "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
        "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n",
        "    url, sha1_hash = DATA_HUB[name]\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
        "    if os.path.exists(fname):\n",
        "        sha1 = hashlib.sha1()\n",
        "        with open(fname, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(1048576)\n",
        "                if not data:\n",
        "                    break\n",
        "                sha1.update(data)\n",
        "        if sha1.hexdigest() == sha1_hash:\n",
        "            return fname  # 命中缓存\n",
        "    print(f'正在从{url}下载{fname}...')\n",
        "    r = requests.get(url, stream=True, verify=True)\n",
        "    with open(fname, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return fname\n",
        "\n",
        "def download_extract(name, folder=None):  \n",
        "    \"\"\"下载并解压zip/tar文件\"\"\"\n",
        "    fname = download(name)\n",
        "    base_dir = os.path.dirname(fname)\n",
        "    data_dir, ext = os.path.splitext(fname)\n",
        "    if ext == '.zip':\n",
        "        fp = zipfile.ZipFile(fname, 'r')\n",
        "    elif ext in ('.tar', '.gz'):\n",
        "        fp = tarfile.open(fname, 'r')\n",
        "    else:\n",
        "        assert False, '只有zip/tar文件可以被解压缩'\n",
        "    fp.extractall(base_dir)\n",
        "    return os.path.join(base_dir, folder) if folder else data_dir\n",
        "\n",
        "def download_all():  \n",
        "    \"\"\"下载DATA_HUB中的所有文件\"\"\"\n",
        "    for name in DATA_HUB:\n",
        "        download(name)"
      ],
      "metadata": {
        "id": "SkZuE0tvXRxN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UqHpeTOIT7j1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_HUB['kaggle_house_train'] = (  \n",
        "    DATA_URL + 'kaggle_house_pred_train.csv',\n",
        "    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n",
        "\n",
        "DATA_HUB['kaggle_house_test'] = (  \n",
        "    DATA_URL + 'kaggle_house_pred_test.csv',\n",
        "    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n",
        "train_data = pd.read_csv(download('kaggle_house_train'))\n",
        "test_data = pd.read_csv(download('kaggle_house_test'))\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AY1GA4QXKv5",
        "outputId": "1d6ace45-407d-415f-be04-de016dcdbf91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 81)\n",
            "(1459, 80)\n",
            "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
            "0   1          60       RL         65.0       WD        Normal     208500\n",
            "1   2          20       RL         80.0       WD        Normal     181500\n",
            "2   3          60       RL         68.0       WD        Normal     223500\n",
            "3   4          70       RL         60.0       WD       Abnorml     140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
      ],
      "metadata": {
        "id": "mj_kL620YCEM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#数据的预处理"
      ],
      "metadata": {
        "id": "-5JMzbLlYJry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 若无法获得测试数据，则可根据训练数据计算均值和标准差\n",
        "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
        "all_features[numeric_features] = all_features[numeric_features].apply(\n",
        "    lambda x: (x - x.mean()) / (x.std()))\n",
        "# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
        "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
        "# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征\n",
        "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
        "all_features.shape\n",
        "n_train = train_data.shape[0]\n",
        "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)\n",
        "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)\n",
        "train_labels = torch.tensor(\n",
        "    train_data.SalePrice.values.reshape(-1, 1), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "cWr0s-OeYDOc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#下面是自己的训练代码"
      ],
      "metadata": {
        "id": "pt46FT1OZIKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pvvGIxHuZ3TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "print(train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8yg78vWZMh1",
        "outputId": "0ac8be7c-7eba-49bb-e393-10ff2a4d1fc6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1460, 331])\n",
            "torch.Size([1459, 331])\n",
            "torch.Size([1460, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "迭代器"
      ],
      "metadata": {
        "id": "7VjxtB2kbIm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_iter(batch_size, features, labels):\n",
        "    num_examples = len(features)\n",
        "    indices = list(range(num_examples))\n",
        "    # 这些样本是随机读取的，没有特定的顺序\n",
        "    random.shuffle(indices)\n",
        "    for i in range(0, num_examples, batch_size):\n",
        "        batch_indices = torch.tensor(\n",
        "            indices[i: min(i + batch_size, num_examples)])\n",
        "        yield features[batch_indices], labels[batch_indices]"
      ],
      "metadata": {
        "id": "_DGlmRHjaN0U"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#初始化模型参数,设置256个隐藏层\n",
        "W1 = torch.normal(0, 0.01, size=(331,256), requires_grad=True)\n",
        "W2 = torch.normal(0, 0.01, size=(256,1),requires_grad=True)\n",
        "b1 = torch.zeros(256,requires_grad=True)\n",
        "b2 = torch.zeros(1,requires_grad=True)\n"
      ],
      "metadata": {
        "id": "Dnwnwp6PbH5k"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#激活函数\n",
        "def relu(X):\n",
        "    a = torch.zeros_like(X)\n",
        "    return torch.max(X, a)"
      ],
      "metadata": {
        "id": "GogIdq4Tfnbk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算模型\n",
        "def net(X,W1,W2,b1,b2):\n",
        "    H = relu(X@W1 + b1)  \n",
        "    return (H@W2 + b2)"
      ],
      "metadata": {
        "id": "g-ZqVTTJcToC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#损失函数\n",
        "def loss(y_hat,y):\n",
        "  return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2"
      ],
      "metadata": {
        "id": "Rw4n8t8Ceolr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(params, lr, batch_size):\n",
        "    \"\"\"小批量随机梯度下降\"\"\"\n",
        "    with torch.no_grad():\n",
        "        for param in params:\n",
        "            param -= lr * param.grad / batch_size\n",
        "            param.grad.zero_()"
      ],
      "metadata": {
        "id": "S--wDeIElxGa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10 #读入块的大小\n",
        "num_epoch = 10 #简单训练一百次\n",
        "lr = 0.01\n",
        "for each_epoch in range(num_epoch):\n",
        "  for X,y in data_iter(batch_size,train_features,train_labels):\n",
        "    l = loss(net(X,W1,W2,b1,b2),y)\n",
        "    l.sum().backward()\n",
        "    sgd([W1, b1,W2,b2], lr, batch_size)\n",
        "  with torch.no_grad():\n",
        "    train_l = loss(net(train_features, W1, W2,b1,b2), train_labels)\n",
        "    print(f'epoch {each_epoch + 1}, loss {float(train_l.mean()):f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKLYhPi-hF2p",
        "outputId": "d3db6282-f833-4290-8681-34acb2650fcd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss nan\n",
            "epoch 2, loss nan\n",
            "epoch 3, loss nan\n",
            "epoch 4, loss nan\n",
            "epoch 5, loss nan\n",
            "epoch 6, loss nan\n",
            "epoch 7, loss nan\n",
            "epoch 8, loss nan\n",
            "epoch 9, loss nan\n",
            "epoch 10, loss nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CptzWDawnTIn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}